{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Classification (DecisionTree_KNN_LogisticRegression).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ5_unqb7nO0",
        "colab_type": "text"
      },
      "source": [
        "## Data Understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUG1hmWp7nO4",
        "colab_type": "text"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA385B8D7nO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3f4a3b49-fa1f-48f2-bebd-fff60ebaa0df"
      },
      "source": [
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxJ0SsHX7nPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "35de4796-b0e8-44a6-ac21-d3b63865aad0"
      },
      "source": [
        "#Import packages and read data\n",
        "bank = pd.read_csv('Bank_Personal_Loan_Modelling.csv')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1443db918ab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Import packages and read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bank_Personal_Loan_Modelling.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File Bank_Personal_Loan_Modelling.csv does not exist: 'Bank_Personal_Loan_Modelling.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xZkE9zt7nPY",
        "colab_type": "text"
      },
      "source": [
        "### Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm-_fDtG7nPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# No missing data\n",
        "print(bank.info())\n",
        "\n",
        "# No duplicated data\n",
        "print(sum(bank.duplicated()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrmOMG7q7nPm",
        "colab_type": "text"
      },
      "source": [
        "### Data Description & Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K1SzF-H7nPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#First few rows of data\n",
        "bank.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llbh1CoD7nPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#number of columns and rows\n",
        "bank.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHgIf2sI7nP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#List all the column names\n",
        "bank.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM5mgRXJ7nQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Descriptive statistics for numeric attributes\n",
        "bank.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mioteuRN7nQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binary categories: target variable personal loan, also securities account, CD account, online banking and credit card. \n",
        "# Counts of both classes in binary variables\n",
        "\n",
        "## Personal loan - Did this customer accept the personal loan offered in the last campaign? This is our target variable\n",
        "print(bank['Personal Loan'].value_counts(dropna = False))\n",
        "\n",
        "## Securities Account - Does the customer have a securities account with the bank?\n",
        "print(bank['Securities Account'].value_counts(dropna = False))\n",
        "\n",
        "## CD Account - Does the customer have a certificate of deposit (CD) account with the bank?\n",
        "print(bank['CD Account'].value_counts(dropna = False))\n",
        "\n",
        "## Online - Does the customer use internet banking facilities?\n",
        "print(bank['Online'].value_counts(dropna = False))\n",
        "\n",
        "## Credit Card - Does the customer use a credit card issued by UniversalBank?\n",
        "print(bank['CreditCard'].value_counts(dropna = False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MdjtpTCS7nQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interval categories: experience, age, income, CC avg and mortgage.\n",
        "\n",
        "## Experience - Year of experience (negative values!!!)\n",
        "print(bank.loc[bank.Experience < 0].head())\n",
        "print(len(bank[bank.Experience < 0]))    # 52 negative\n",
        "\n",
        "## Age - \n",
        "bank.Age.plot('hist')\n",
        "plt.title(\"Age\")\n",
        "plt.show()\n",
        "\n",
        "## Income - Annual income in dollars (which income, what the scale is?)\n",
        "bank.Income.plot('hist')\n",
        "plt.title(\"Income\")\n",
        "plt.show()\n",
        "\n",
        "## CCAvg - Average credit card spending\n",
        "bank['CCAvg'].plot('hist')\n",
        "plt.title(\"CCAvg\")\n",
        "plt.show()\n",
        "\n",
        "## Mortgage - Value of House Mortgage\n",
        "bank['Mortgage'].plot('hist')\n",
        "plt.title(\"Mortgage\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B0fBdiA7nQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ordinal categories: family and education\n",
        "\n",
        "# Family (mostly 1)\n",
        "print(bank['Family'].value_counts())\n",
        "\n",
        "# Education - Education level of the customer (mostly 1)\n",
        "print(bank['Education'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSHjDT6u7nQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Counts for target variable\n",
        "## Personal loan - Did this customer accept the personal loan offered in the last campaign? This is our target variable\n",
        "print(bank['Personal Loan'].value_counts(dropna = False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW8JenlP7nQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bar plot visualizing two classes in the target variable\n",
        "count = bank[\"Personal Loan\"].value_counts()\n",
        "count.plot(kind = \"bar\", title = \"count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6gIRrns7nRB",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WACFtgdh7nRD",
        "colab_type": "text"
      },
      "source": [
        "### Deal with Negative Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykDyyROG7nRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deal with negative values in Experience\n",
        "## Replace with the median experience from people having the same age\n",
        "bank_Age = bank[bank.Experience >= 0].groupby('Age').Experience.median().to_frame('Experience Median').reindex()\n",
        "bank = pd.merge(bank, bank_Age, on = \"Age\", how = \"left\")\n",
        "\n",
        "# Round up the value to an integer\n",
        "bank.loc[bank.Experience < 0, 'Experience'] = np.round(bank['Experience Median'])\n",
        "\n",
        "# 23 years old == null\n",
        "## Since no one in the dataset aged 23 had reported accurate experience, and based on that of 22 and 24, we replace negative values with 0.\n",
        "bank.loc[bank.Experience.isnull(), 'Experience'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PwyRwpS7nRO",
        "colab_type": "text"
      },
      "source": [
        "### Categorized Categorical Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgcQ4pEc7nRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ZIP Code\n",
        "bank['ZIP Code'] = bank['ZIP Code'].astype(str)\n",
        "bank['Area'] = bank['ZIP Code'].str.slice(0, 3)\n",
        "bank['Area'] = bank['Area'].astype('category')\n",
        "bank['ZIP Code'] = bank['ZIP Code'].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rkKIn4U7nRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Education, Family\n",
        "bank['Education'] = bank['Education'].astype('category')\n",
        "bank['Family'] = bank['Family'].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD3PBD8D7nRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show all the data types\n",
        "bank.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHyHnWAY7nRt",
        "colab_type": "text"
      },
      "source": [
        "### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnNS1f0Y7nRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop unnecessary columns in order to plot the correlation plot.\n",
        "bank.drop(['ID', 'Experience Median', 'ZIP Code'],  inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wjg25V7r7nR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = bank.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "\n",
        "corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hu5GoFg7nSC",
        "colab_type": "text"
      },
      "source": [
        "### Dummy Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nev_FUHl7nSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Family\n",
        "## Family has 4 levels, and we create 3 dummy variables\n",
        "\n",
        "familydummy = pd.get_dummies(bank['Family'], prefix='Family')\n",
        "bank_family = pd.concat([bank, familydummy], axis=1)      \n",
        "bank_family.drop(['Family_4'], inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBY7_iU97nSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Education\n",
        "## Education has 3 levels, and we create 2 dummy variables\n",
        "\n",
        "edudummy =  pd.get_dummies(bank_family['Education'], prefix='Education')\n",
        "bank_edu = pd.concat([bank_family, edudummy], axis=1)      \n",
        "bank_edu.drop(['Education_3'], inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GMsYdxx7nSU",
        "colab_type": "text"
      },
      "source": [
        "### Describe Cleaned Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4xrdicF7nSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Total numbers of rows and columns\n",
        "bank_edu.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEfsu1G77nSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Descriptive statistics of the cleaned dataset\n",
        "bank_edu.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7TwQdG87nSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List all the column names\n",
        "list(bank_edu.columns.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsOU3fHB7nS0",
        "colab_type": "text"
      },
      "source": [
        "### Define Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvSh4k-I7nS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We define two x here\n",
        "## x is used for KNN and Logistic Regression. This model contains dummy variables.\n",
        "## xtree is used for decision tree. This model treated Family and Education as categorical variables. \n",
        "##  Targe variable is 'Personal Loan'\n",
        "\n",
        "x = bank_edu[['Age',\n",
        " 'Income',\n",
        " 'CCAvg',\n",
        " 'Mortgage',\n",
        " 'Securities Account',\n",
        " 'CD Account',\n",
        " 'Online',\n",
        " 'CreditCard',\n",
        " 'Family_1',\n",
        " 'Family_2',\n",
        " 'Family_3',\n",
        " 'Education_1',\n",
        " 'Education_2']]\n",
        "\n",
        "xtree = bank_edu[[ 'Age',\n",
        " 'Income',\n",
        " 'Family',\n",
        " 'CCAvg',\n",
        " 'Education',\n",
        " 'Mortgage',\n",
        " 'Securities Account',\n",
        " 'CD Account',\n",
        " 'Online',\n",
        " 'CreditCard',\n",
        " 'Area']]\n",
        "\n",
        "y = bank_edu[\"Personal Loan\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR2Dvpze7nS_",
        "colab_type": "text"
      },
      "source": [
        "### Train/Test Data Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nsgztGs7nTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split Data for KNN and Logistic Regression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=0, stratify = y)\n",
        "x_train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLKAmzVJ7nTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data for decision tree\n",
        "\n",
        "xtree_train, xtree_test, y_train, y_test = train_test_split(xtree, y, test_size=0.30, random_state=0, stratify = y)\n",
        "xtree_train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6YDq9ay7nTP",
        "colab_type": "text"
      },
      "source": [
        "## Modeling & Evaluation (Pre-Resample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsWvZp3M7nTR",
        "colab_type": "text"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3mlptsK7nTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use GridSearch to find the best decision tree parameters, and fit the training data to apply to test data\n",
        "\n",
        "from sklearn import tree\n",
        "import sklearn.grid_search as gs\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "\n",
        "gstree = gs.GridSearchCV(estimator=DecisionTreeClassifier(random_state=0),\n",
        "                                   param_grid= [{\"criterion\": [\"gini\", \"entropy\"],\n",
        "                                                 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50],\n",
        "                                                 \"max_features\": list(range(1, 11)),\n",
        "                                                 'min_samples_leaf':[1,2,3,4,5],\n",
        "                                                 'min_samples_split':[2,3,4,5]\n",
        "                                                }],\n",
        "                                   cv = 10,\n",
        "                                   n_jobs = 4,\n",
        "                                   scoring='accuracy')\n",
        "gstree_fit = gstree.fit(xtree_train, y_train)\n",
        "y_pred_tree = gstree_fit.predict(xtree_test)\n",
        "\n",
        "## best parameter\n",
        "print(gstree.best_params_)\n",
        "\n",
        "## best estimator\n",
        "print(\"Tree parameters: \\n\", gstree_fit.best_estimator_)\n",
        "\n",
        "## best score\n",
        "print(\"Best score: \", gstree.best_score_)\n",
        "\n",
        "## The overall accuracy on the training set:\n",
        "print(\"Training score: \", gstree.score(xtree_train, y_train))\n",
        "\n",
        "## The overall accuracy on the test set:\n",
        "print(\"Test accuracy: \", gstree.score(xtree_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "tEwTnmXf7nTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generalization Performance of decision tree on test data\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "\n",
        "accuracy = sum(y_pred_tree == y_test)/len(y_test)\n",
        "error = 1 - accuracy\n",
        "print(\"The predictive accuracy is: \", round(accuracy, 2))\n",
        "print(\"The classification error is: \", round(error, 2))\n",
        "print(classification_report(y_test, y_pred_tree))\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cnf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred_tree), columns = ['Predict 0', 'Predict 1'], index = ['Actual 0', 'Actual 1'])\n",
        "print(\"The Confusion matrix: \\n\", cnf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktiF0e8j7nTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Graph for the best decision tree model\n",
        "\n",
        "from sklearn import tree\n",
        "import graphviz \n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "model =  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
        "            max_features=10, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=1, min_samples_split=3,\n",
        "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
        "            splitter='best')\n",
        "model = model.fit(xtree_train, y_train)\n",
        "\n",
        "dot_data = tree.export_graphviz(model, out_file=None, \n",
        "                                feature_names = [ 'Age', 'Income', 'Family', 'CCAvg', 'Education', 'Mortgage', \n",
        "                                                 'Securities Account', 'CD Account', 'Online', 'CreditCard', 'Area'],\n",
        "                                class_names = ['0','1'],\n",
        "                                filled = True, \n",
        "                                rounded = True)\n",
        "                                                   \n",
        "graph = graphviz.Source(dot_data) \n",
        "graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni_U4lUj7nTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cross Validation score for decision tree\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores_tree=cross_val_score(gstree, xtree_train, y_train, \n",
        "                         scoring='accuracy', cv=10)\n",
        "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores_tree), np.std(scores_tree)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG9yve-O7nT1",
        "colab_type": "text"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO-x9Xkq7nT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standardize for x (both training and test data)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "sc.fit(x_train)\n",
        "x_train_std = sc.transform(x_train)\n",
        "x_test_std = sc.transform(x_test)\n",
        "x_std = sc.transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgVqpujN7nT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use GridSearch to find the best KNN parameters, and fit the training data to apply to test data.\n",
        "\n",
        "from sklearn import neighbors, datasets\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "gsknn = GridSearchCV(estimator=neighbors.KNeighborsClassifier(p=2, \n",
        "                           metric='minkowski'),\n",
        "                  param_grid=[{'n_neighbors': [1,3,5,7,9,11,13,15,17,19,21],\n",
        "                               'weights':['uniform','distance']}],\n",
        "                  scoring='accuracy',\n",
        "                  cv=10,\n",
        "                  n_jobs=4)\n",
        "\n",
        "gsknn_fit = gsknn.fit(x_train_std, y_train)          \n",
        "y_pred_knn = gsknn_fit.predict(x_test_std)\n",
        "\n",
        "## best parameter\n",
        "print(gsknn.best_params_)\n",
        "\n",
        "## best estimator\n",
        "print(\"KNN parameters: \\n\", gsknn_fit.best_estimator_)\n",
        "\n",
        "## best score\n",
        "print(\"Best score: \", gsknn.best_score_)\n",
        "\n",
        "## The overall accuracy on the training set:\n",
        "print(\"Training score: \", gsknn.score(x_train_std, y_train))\n",
        "\n",
        "## The overall accuracy on the test set:\n",
        "print(\"Test accuracy: \", gsknn.score(x_test_std, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIjqkjVH7nUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generalization Performance of KNN on test data\n",
        "\n",
        "accuracy = sum(y_pred_knn == y_test)/len(y_test)\n",
        "error = 1 - accuracy\n",
        "print(\"The predictive accuracy is: \", round(accuracy, 2))\n",
        "print(\"The classification error is: \", round(error, 2))\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Confusion matrix\n",
        "cnf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred_knn), columns = ['Predict 0', 'Predict 1'], index = ['Actual 0', 'Actual 1'])\n",
        "print(\"The Confusion matrix: \\n\", cnf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKUc9vAG7nUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross Validation score for KNN model\n",
        "\n",
        "scores_knn =cross_val_score(gsknn, x_train_std, y_train, \n",
        "                         scoring='accuracy', cv=10)\n",
        "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores_knn), np.std(scores_knn)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyjuyqvJ7nUR",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oUcOwbH7nUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use GridSearch to find the best logistic regression parameters, and fit the training data to apply to test data.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "\n",
        "gslr = GridSearchCV(estimator=LogisticRegression(random_state=0),\n",
        "                  param_grid=[{'C': [ 0.00001, 0.0001, 0.001, 0.01, 0.1 ,1 ,10 ,100, 1000, 10000, 100000, 1000000, 10000000],\n",
        "                             'penalty':['l1','l2']}],\n",
        "                  scoring='accuracy',\n",
        "                  cv=10)\n",
        "\n",
        "gslr_fit = gslr.fit(x_train, y_train)          \n",
        "y_pred_lr = gslr_fit.predict(x_test)\n",
        "\n",
        "## best parameter\n",
        "print(gslr.best_params_)\n",
        "\n",
        "## best estimator\n",
        "print(\"Logistic parameters: \\n\", gslr_fit.best_estimator_)\n",
        "\n",
        "## best score\n",
        "print(\"Best score: \", gslr.best_score_)\n",
        "\n",
        "## The overall accuracy on the training set:\n",
        "print(\"Training score: \", gslr.score(x_train, y_train))\n",
        "\n",
        "## The overall accuracy on the test set:\n",
        "print(\"Test accuracy: \", gslr.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1OLtb-57nUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generalization Performance of logistic regression on test data\n",
        "\n",
        "accuracy = sum(y_pred_lr == y_test)/len(y_test)\n",
        "error = 1 - accuracy\n",
        "print(\"The predictive accuracy is: \", round(accuracy, 2))\n",
        "print(\"The classification error is: \", round(error, 2))\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# Confusion matrix\n",
        "\n",
        "cnf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred_lr), columns = ['Predict 0', 'Predict 1'], index = ['Actual 0', 'Actual 1'])\n",
        "print(\"The Confusion matrix: \\n\", cnf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ju-UUEr7nUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross validation performance for logistic regression \n",
        "\n",
        "scores_lr =cross_val_score(gslr, x_train, y_train, \n",
        "                         scoring='accuracy', cv=10)\n",
        "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores_lr),np.std(scores_knn)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPeMlcoH7nUi",
        "colab_type": "text"
      },
      "source": [
        "### ROC Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CPq2gBo57nUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROC graph containing roc curve for decision tree, KNN, and logistic regression models\n",
        "\n",
        "np.random.seed(0)\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "## Decision Tree Classifier\n",
        "clf1 = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
        "            max_features=10, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=1, min_samples_split=3,\n",
        "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
        "            splitter='best')\n",
        "\n",
        "## kNN Classifier\n",
        "clf2 = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
        "           weights='uniform')\n",
        "\n",
        "## Logistic Regression Classifier\n",
        "clf3 = LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
        "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
        "          verbose=0, warm_start=False)\n",
        "\n",
        "# Label the classifiers\n",
        "clf_labels = ['Decision tree',  'KNN', 'Logistic regression',]\n",
        "all_clf = [clf1, clf2, clf3]\n",
        "\n",
        "print('10-fold cross validation:\\n')\n",
        "for clf, label in zip([clf1, clf2, clf3], clf_labels): #For all classifiers \n",
        "    if clf == clf1:\n",
        "        scores = cross_val_score(estimator=clf,  #Estimate AUC based on cross validation\n",
        "                             X=xtree_train,\n",
        "                             y=y_train,\n",
        "                             cv=10,\n",
        "                             scoring='roc_auc')\n",
        "\n",
        "    elif clf == clf2:\n",
        "        scores = cross_val_score(estimator=clf,  #Estimate AUC based on cross validation\n",
        "                             X=x_train_std,\n",
        "                             y=y_train,\n",
        "                             cv=10,\n",
        "                             scoring='roc_auc')\n",
        "\n",
        "    else:\n",
        "        scores = cross_val_score(estimator=clf,  #Estimate AUC based on cross validation\n",
        "                             X=x_train,\n",
        "                             y=y_train,\n",
        "                             cv=10,\n",
        "                             scoring='roc_auc')\n",
        "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" #Print peformance statistics based on cross-validation\n",
        "      % (scores.mean(), scores.std(), label))\n",
        "\n",
        "colors = ['red', 'blue', 'green']      #Colors for visualization\n",
        "linestyles = [':', '--', '-.', '-']        #Line styles for visualization\n",
        "for clf, label, clr, ls in zip(all_clf,\n",
        "               clf_labels, colors, linestyles):\n",
        "\n",
        "    # assuming the label of the positive class is 1 and data is normalized\n",
        "    if clf == clf1:\n",
        "        y_pred = clf.fit(xtree_train,\n",
        "                         y_train).predict_proba(xtree_test)[:, 1] # Make predictions based on the classifiers\n",
        "        \n",
        "    elif clf == clf2:\n",
        "        y_pred = clf.fit(x_train_std,\n",
        "                         y_train).predict_proba(x_test_std)[:, 1] # Make predictions based on the classifiers\n",
        "        \n",
        "    else:\n",
        "        y_pred = clf.fit(x_train,\n",
        "                         y_train).predict_proba(x_test)[:, 1] # Make predictions based on the classifiers\n",
        "    fpr, tpr, thresholds = roc_curve(y_true=y_test, # Build ROC curve\n",
        "                                     y_score=y_pred)\n",
        "    roc_auc = auc(x=fpr, y=tpr)                # Compute Area Under the Curve (AUC) \n",
        "    plt.plot(fpr, tpr,                         # Plot ROC Curve and create label with AUC values\n",
        "             color=clr,\n",
        "             linestyle=ls,\n",
        "             label='%s (auc = %0.2f)' % (label, roc_auc))\n",
        "\n",
        "plt.legend(loc='lower right')    # Where to place the legend\n",
        "plt.plot([0, 1], [0, 1], # Visualize random classifier\n",
        "         linestyle='--',\n",
        "         color='gray',\n",
        "         linewidth=2)\n",
        "\n",
        "plt.xlim([-0.1, 1.1])   #limits for x axis\n",
        "plt.ylim([-0.1, 1.1])   #limits for y axis\n",
        "plt.grid(alpha=0.5)\n",
        "plt.xlabel('False positive rate (FPR)')\n",
        "plt.ylabel('True positive rate (TPR)')\n",
        "\n",
        "\n",
        "#plt.savefig('ROC_all_classifiers', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmRoy9JO7nUp",
        "colab_type": "text"
      },
      "source": [
        "## Modling & Evalutaion (Resampling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrkonxcJ7nUq",
        "colab_type": "text"
      },
      "source": [
        "### Resampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqOPQ_3D7nUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The dataset is imbalanced, we resample the rare class to the same amount of the larger class to get 50%:50% ratio.\n",
        "# We only resample for the training dataset, excluding test data\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "## resample for KNN and logistic regression\n",
        "x_train_resampled, y_train_resampled = resample(x_train[ y_train == 1],\n",
        "                                    y_train[y_train == 1],\n",
        "                                    replace=True, \n",
        "                                    n_samples=x_train[y_train == 0].shape[0], \n",
        "                                    random_state=0)\n",
        "\n",
        "xtree_train_resampled, y_train_resampled = resample(xtree_train[y_train == 1],\n",
        "                                    y_train[y_train == 1],\n",
        "                                    replace=True, \n",
        "                                    n_samples=xtree_train[y_train == 0].shape[0], \n",
        "                                    random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY-5T0DV7nUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## resample for decision tree\n",
        "\n",
        "x_train_zero = x_train[y_train == 0]\n",
        "x_train_resample = pd.concat([x_train_resampled, x_train_zero])\n",
        "\n",
        "xtree_train_zero = xtree_train[y_train == 0]\n",
        "xtree_train_resample = pd.concat([xtree_train_resampled, xtree_train_zero])\n",
        "\n",
        "y_train_zero = y_train[y_train == 0]\n",
        "y_train_resample = pd.concat([y_train_resampled, y_train_zero])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoDFco8h7nU6",
        "colab_type": "text"
      },
      "source": [
        "### Decision Tree (Resampling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BPbycfVJ7nU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use GridSearch to find the best decision tree parameters after resampling, and fit the training data to apply to test data\n",
        "from sklearn import tree\n",
        "import sklearn.grid_search as gs\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "\n",
        "gstree_resample = gs.GridSearchCV(estimator=DecisionTreeClassifier(random_state=0),\n",
        "                                   param_grid= [{\"criterion\": [\"gini\", \"entropy\"],\n",
        "                                                 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50],\n",
        "                                                 \"max_features\": list(range(1, 11)),\n",
        "                                                 'min_samples_leaf':[1,2,3,4,5],\n",
        "                                                 'min_samples_split':[2,3,4,5]\n",
        "                                                }],\n",
        "                                   cv = 10,\n",
        "                                   n_jobs = 4,\n",
        "                                   scoring='accuracy')\n",
        "gstree_resample_fit = gstree_resample.fit(xtree_train_resample, y_train_resample)\n",
        "y_pred_tree_resample = gstree_resample_fit.predict(xtree_test)\n",
        "\n",
        "## best parameter\n",
        "print(gstree_resample.best_params_)\n",
        "\n",
        "## best estimator\n",
        "print(\"Tree parameters: \\n\", gstree_resample_fit.best_estimator_)\n",
        "\n",
        "## best score\n",
        "print(\"Best score: \", gstree_resample.best_score_)\n",
        "\n",
        "## The overall accuracy on the training set:\n",
        "print(\"Training score: \", gstree_resample.score(xtree_train_resample, y_train_resample))\n",
        "\n",
        "## The overall accuracy on the test set:\n",
        "print(\"Test accuracy: \", gstree_resample.score(xtree_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn8VKMkd7nVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=20,\n",
        "            max_features=10, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
        "            splitter='best').fit(xtree_train_resample, y_train_resample)\n",
        "tree.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IZF1WEd57nVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtree_train_resample.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rClFLDNa7nVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_importance = pd.DataFrame({'features': list(xtree_train_resample.columns), 'importance': list(tree.feature_importances_)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjXtVGbn7nVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = feature_importance.sort_values('importance', ascending = False)\n",
        "tmp.plot('features', 'importance', kind = 'bar', color = 'black', legend = None)\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Importance')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "p9WwIuvG7nVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generalization Performance of decision tree after resampling on test data\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "\n",
        "accuracy = sum(y_pred_tree_resample == y_test)/len(y_test)\n",
        "error = 1 - accuracy\n",
        "print(\"The predictive accuracy is: \", round(accuracy, 2))\n",
        "print(\"The classification error is: \", round(error, 2))\n",
        "print(classification_report(y_test, y_pred_tree_resample))\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cnf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred_tree_resample), columns = ['Predict 0', 'Predict 1'], index = ['Actual 0', 'Actual 1'])\n",
        "print(\"The Confusion matrix: \\n\", cnf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYlJm71R7nVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "\n",
        "def image_path(fig_id):\n",
        "    return os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(image_path(fig_id) + \".png\", format='png', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV-FQawa7nVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Graph for the best decision tree model\n",
        "\n",
        "from sklearn import tree\n",
        "import graphviz \n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "model =  DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=20,\n",
        "            max_features=10, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
        "            splitter='best')\n",
        "model = model.fit(xtree_train_resample, y_train_resample)\n",
        "\n",
        "dot_data = tree.export_graphviz(model, out_file=image_path(\"of_tree.dot\"), \n",
        "                                feature_names = [ 'Age', 'Income', 'Family', 'CCAvg', 'Education', 'Mortgage', \n",
        "                                                 'Securities Account', 'CD Account', 'Online', 'CreditCard', 'Area'],\n",
        "                                class_names = ['0','1'],\n",
        "                                filled = True, \n",
        "                                rounded = True)\n",
        "                                                   \n",
        "graph = graphviz.Source(dot_data) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9vDCZks7nVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting .dot file to PNG Example: Run command \"dot -Tpng of_tree.dot -o of_tree.png\" in the terminal after installing graphviz package \n",
        "# and making sure you are in the right directory (same directory as the .dot file)\n",
        "path_png = os.path.join(PROJECT_ROOT_DIR, \"images\", \"of_tree.png\")\n",
        "Image(path_png)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jma-4JEU7nVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross Validation score for decision tree after resampling \n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores_tree_resample=cross_val_score(gstree, xtree_train_resample, y_train_resample, \n",
        "                         scoring='accuracy', cv=10)\n",
        "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores_tree_resample), np.std(scores_tree_resample)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AUpCPfz7nVx",
        "colab_type": "text"
      },
      "source": [
        "### KNN (Resampling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk0IYTBU7nVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standardize for all x after resampling\n",
        "\n",
        "sc.fit(x_train_resample)\n",
        "x_train_resample_std = sc.transform(x_train_resample)\n",
        "x_test_std = sc.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcbHVOo67nV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use GridSearch to find the best KNN parameters after resampling, and fit the training data to apply to test data\n",
        "\n",
        "gsknn_resample = GridSearchCV(estimator=neighbors.KNeighborsClassifier(p=2, \n",
        "                           metric='minkowski'),\n",
        "                  param_grid=[{'n_neighbors': [1,3,5,7,9,11,13,15,17,19,21],\n",
        "                               'weights':['uniform','distance']}],\n",
        "                  scoring='accuracy',\n",
        "                  cv=10,\n",
        "                  n_jobs=4)\n",
        "\n",
        "gsknn_resample_fit = gsknn_resample.fit(x_train_resample_std, y_train_resample)          \n",
        "y_pred_knn_resample = gsknn_resample_fit.predict(x_test_std)\n",
        "\n",
        "## best parameter\n",
        "print(gsknn_resample.best_params_)\n",
        "\n",
        "## best estimator\n",
        "print(\"KNN parameters: \\n\", gsknn_resample_fit.best_estimator_)\n",
        "\n",
        "## best score\n",
        "print(\"Best score: \", gsknn_resample.best_score_)\n",
        "\n",
        "## The overall accuracy on the training set:\n",
        "print(\"Training score: \", gsknn_resample.score(x_train_resample_std, y_train_resample))\n",
        "\n",
        "## The overall accuracy on the test set:\n",
        "print(\"Test accuracy: \", gsknn_resample.score(x_test_std, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UAPnWCu7nV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generalization Performance of KNN after resampling on test data\n",
        "\n",
        "accuracy = sum(y_pred_knn_resample == y_test)/len(y_test)\n",
        "error = 1 - accuracy\n",
        "print(\"The predictive accuracy is: \", round(accuracy, 2))\n",
        "print(\"The classification error is: \", round(error, 2))\n",
        "print(classification_report(y_test, y_pred_knn_resample))\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cnf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred_knn_resample), columns = ['Predict 0', 'Predict 1'], index = ['Actual 0', 'Actual 1'])\n",
        "print(\"The Confusion matrix: \\n\", cnf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEmfHD0u7nV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross validaiton score for KNN after resampling\n",
        "\n",
        "scores_knn_resample =cross_val_score(gsknn_resample, x_train_resample_std, y_train_resample, \n",
        "                         scoring='accuracy', cv=10)\n",
        "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores_knn_resample), np.std(scores_knn_resample)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzqOfU4F7nWC",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression (Resampling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1HOyjE37nWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use GridSearch to find the best logistic regression parameters after resampling, and fit the training data to apply to test data.\n",
        "\n",
        "gslr_resample = GridSearchCV(estimator=LogisticRegression(random_state=0),\n",
        "                  param_grid=[{'C': [ 0.00001, 0.0001, 0.001, 0.01, 0.1 ,1 ,10 ,100, 1000, 10000, 100000, 1000000, 10000000],\n",
        "                             'penalty':['l1','l2']}],\n",
        "                  scoring='accuracy',\n",
        "                  cv=10)\n",
        "\n",
        "gslr_resample_fit = gslr_resample.fit(x_train_resample, y_train_resample)          \n",
        "y_pred_lr_resample = gslr_resample_fit.predict(x_test)\n",
        "\n",
        "## best parameter\n",
        "print(gslr_resample.best_params_)\n",
        "\n",
        "## best estimator\n",
        "print(\"Logistic parameters: \\n\", gslr_resample_fit.best_estimator_)\n",
        "\n",
        "## best score\n",
        "print(\"Best score: \", gslr_resample.best_score_)\n",
        "\n",
        "## The overall accuracy on the training set:\n",
        "print(\"Training score: \", gslr_resample.score(x_train_resample, y_train_resample))\n",
        "\n",
        "## The overall accuracy on the test set:\n",
        "print(\"Test accuracy: \", gslr_resample.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iro5D2tg7nWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generalization Performance of logistic regression after resampling on test data\n",
        "\n",
        "accuracy = sum(y_pred_lr_resample == y_test)/len(y_test)\n",
        "error = 1 - accuracy\n",
        "print(\"The predictive accuracy is: \", round(accuracy, 2))\n",
        "print(\"The classification error is: \", round(error, 2))\n",
        "print(classification_report(y_test, y_pred_lr_resample))\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cnf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred_lr_resample), columns = ['Predict 0', 'Predict 1'], index = ['Actual 0', 'Actual 1'])\n",
        "print(\"The Confusion matrix: \\n\", cnf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhCk060S7nWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross validation score for logisitc regression after resampling\n",
        "\n",
        "scores_lr_resample =cross_val_score(gslr_resample, x_train_resample, y_train_resample, \n",
        "                                    scoring='accuracy', cv=10)\n",
        "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores_lr_resample), np.std(scores_lr_resample)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWBPVjwK7nWO",
        "colab_type": "text"
      },
      "source": [
        "### ROC Graph (Resampling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN53I-Yk7nWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROC graph containing roc curve for decision tree, KNN, and logistic regression models after resampling\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "## Decision Tree Classifier\n",
        "clf1_resample = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=20,\n",
        "            max_features=10, max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
        "            splitter='best')\n",
        "\n",
        "## kNN Classifier\n",
        "clf2_resample = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
        "           weights='uniform')\n",
        "\n",
        "## Logistic Regression Classifier\n",
        "clf3_resample = LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
        "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
        "          verbose=0, warm_start=False)\n",
        "\n",
        "# Label the classifiers\n",
        "clf_labels = ['Decision tree',  'KNN', 'Logistic regression',]\n",
        "all_clf = [clf1_resample, clf2_resample, clf3_resample]\n",
        "\n",
        "print('10-fold cross validation:\\n')\n",
        "for clf, label in zip([clf1_resample, clf2_resample, clf3_resample], clf_labels): #For all classifiers \n",
        "    if clf == clf1_resample:\n",
        "        scores = cross_val_score(estimator=clf,  #Estimate AUC based on cross validation\n",
        "                             X=xtree_train_resample,\n",
        "                             y=y_train_resample,\n",
        "                             cv=10,\n",
        "                             scoring='roc_auc')\n",
        "    elif clf == clf2_resample:\n",
        "        scores = cross_val_score(estimator=clf,  #Estimate AUC based on cross validation\n",
        "                             X=x_train_resample_std,\n",
        "                             y=y_train_resample,\n",
        "                             cv=10,\n",
        "                             scoring='roc_auc')\n",
        "\n",
        "    else:\n",
        "        scores = cross_val_score(estimator=clf,  #Estimate AUC based on cross validation\n",
        "                             X=x_train_resample,\n",
        "                             y=y_train_resample,\n",
        "                             cv=10,\n",
        "                             scoring='roc_auc')\n",
        "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" #Print peformance statistics based on cross-validation\n",
        "      % (scores.mean(), scores.std(), label))\n",
        "\n",
        "colors = ['red', 'blue', 'green']      #Colors for visualization\n",
        "linestyles = [':', '--', '-.', '-']        #Line styles for visualization\n",
        "for clf, label, clr, ls in zip(all_clf,\n",
        "               clf_labels, colors, linestyles):\n",
        "\n",
        "    # assuming the label of the positive class is 1 and data is normalized\n",
        "    if clf == clf1_resample:\n",
        "        y_pred = clf.fit(xtree_train_resample,\n",
        "                         y_train_resample).predict_proba(xtree_test)[:, 1] # Make predictions based on the classifiers\n",
        "        \n",
        "    elif clf == clf2_resample:\n",
        "        y_pred = clf.fit(x_train_resample_std,\n",
        "                         y_train_resample).predict_proba(x_test_std)[:, 1] # Make predictions based on the classifiers\n",
        "\n",
        "    else:\n",
        "        y_pred = clf.fit(x_train_resample,\n",
        "                         y_train_resample).predict_proba(x_test)[:, 1] # Make predictions based on the classifiers\n",
        "    fpr, tpr, thresholds = roc_curve(y_true=y_test, # Build ROC curve\n",
        "                                     y_score=y_pred)\n",
        "    roc_auc = auc(x=fpr, y=tpr)                # Compute Area Under the Curve (AUC) \n",
        "    plt.plot(fpr, tpr,                         # Plot ROC Curve and create label with AUC values\n",
        "             color=clr,\n",
        "             linestyle=ls,\n",
        "             label='%s (auc = %0.2f)' % (label, roc_auc))\n",
        "\n",
        "plt.legend(loc='lower right')    # Where to place the legend\n",
        "plt.plot([0, 1], [0, 1], # Visualize random classifier\n",
        "         linestyle='--',\n",
        "         color='gray',\n",
        "         linewidth=2)\n",
        "\n",
        "plt.xlim([-0.1, 1.1])   #limits for x axis\n",
        "plt.ylim([-0.1, 1.1])   #limits for y axis\n",
        "plt.grid(alpha=0.5)\n",
        "plt.xlabel('False positive rate (FPR)')\n",
        "plt.ylabel('True positive rate (TPR)')\n",
        "\n",
        "#plt.savefig('ROC_all_classifiers', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}